{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836f8d80",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sivaratrisrinivas/ttt-playground/blob/main/notebooks/05_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40897be7",
   "metadata": {},
   "source": [
    "# TTT Playground - Integration Tests\n",
    "\n",
    "End-to-end tests for the full TTT pipeline:\n",
    "1. **Full Pipeline**: PDF → parse → chunk → learn → clear → Q&A\n",
    "2. **Memory Test**: Process large PDF, monitor VRAM\n",
    "3. **Latency Test**: Measure time per chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4eab6d",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93596399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo (or pull latest if exists)\n",
    "import os\n",
    "\n",
    "if os.path.exists('/content/ttt-playground'):\n",
    "    !cd /content/ttt-playground && git pull\n",
    "    %cd /content/ttt-playground\n",
    "else:\n",
    "    !git clone https://github.com/sivaratrisrinivas/ttt-playground.git\n",
    "    %cd ttt-playground\n",
    "\n",
    "# If this runtime previously imported src.*, force reload after git pull\n",
    "import importlib\n",
    "import sys\n",
    "importlib.invalidate_caches()\n",
    "for _m in [m for m in list(sys.modules.keys()) if m == 'src' or m.startswith('src.')]:\n",
    "    del sys.modules[_m]\n",
    "print('✓ Cleared cached src.* modules')\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87218965",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "print(\"✓ Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d0c94",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8.2: Full Pipeline Test\n",
    "\n",
    "PDF → parse → chunk → learn → clear context → Q&A comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test PDF with specific content we can query\n",
    "import fitz\n",
    "\n",
    "def create_content_pdf(filename: str) -> int:\n",
    "    \"\"\"Create PDF with specific facts for testing.\"\"\"\n",
    "    doc = fitz.open()\n",
    "\n",
    "    content = [\n",
    "        \"ACME Corporation Annual Report 2024\",\n",
    "        \"\",\n",
    "        \"Company Overview:\",\n",
    "        \"ACME Corporation was founded in 1985 by John Smith in Silicon Valley.\",\n",
    "        \"The company specializes in manufacturing advanced robotics systems.\",\n",
    "        \"Headquarters is located at 123 Innovation Drive, Palo Alto, CA.\",\n",
    "        \"\",\n",
    "        \"Financial Highlights:\",\n",
    "        \"Revenue for 2024: $4.7 billion\",\n",
    "        \"Net profit margin: 23.5%\",\n",
    "        \"Total employees: 12,500\",\n",
    "        \"\",\n",
    "        \"Key Products:\",\n",
    "        \"1. RoboArm X500 - Industrial robotic arm for manufacturing\",\n",
    "        \"2. AutoNav 3.0 - Autonomous navigation system\",\n",
    "        \"3. SenseAI - Computer vision platform\",\n",
    "        \"\",\n",
    "        \"The CEO is Sarah Johnson, who joined in 2019.\",\n",
    "        \"The CTO is Michael Chen, leading the R&D team of 2,000 engineers.\",\n",
    "    ]\n",
    "\n",
    "    # Repeat content to make document longer for better learning\n",
    "    full_text = \"\\n\".join(content)\n",
    "    for page_num in range(5):  # 5 pages\n",
    "        page = doc.new_page()\n",
    "        page.insert_text((50, 50), f\"Page {page_num + 1}\", fontsize=12)\n",
    "        page.insert_text((50, 80), full_text, fontsize=10)\n",
    "\n",
    "    pages = doc.page_count\n",
    "    doc.save(filename)\n",
    "    doc.close()\n",
    "    print(f\"Created {filename} ({pages} pages)\")\n",
    "    return pages\n",
    "\n",
    "create_content_pdf(\"acme_report.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from src.models.ttt_model import TTTModel\n",
    "\n",
    "model = TTTModel.from_pretrained(\n",
    "    model_name='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "    device='cuda'\n",
    ")\n",
    "print(f\"✓ Model loaded with {len(model.ttt_layers)} TTT layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PDF\n",
    "from src.document.pdf_parser import PDFParser\n",
    "\n",
    "parser = PDFParser()\n",
    "with open(\"acme_report.pdf\", \"rb\") as f:\n",
    "    text, page_count = parser.parse(f.read())\n",
    "\n",
    "print(f\"✓ Parsed PDF: {page_count} pages, {len(text)} chars\")\n",
    "print(f\"Preview: {text[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc897216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk document\n",
    "from src.document.chunker import DocumentChunker\n",
    "\n",
    "chunker = DocumentChunker(model.tokenizer, chunk_size=512)  # smaller chunks for test\n",
    "chunks = chunker.chunk(text)\n",
    "\n",
    "print(f\"✓ Chunked into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"  Chunk {i}: {chunk.token_count} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3051fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document and train\n",
    "from src.config import Document, DocumentStatus, LearningConfig\n",
    "from src.learning.trainer import TTTTrainer\n",
    "\n",
    "doc = Document(\n",
    "    id=\"acme_test\",\n",
    "    filename=\"acme_report.pdf\",\n",
    "    page_count=page_count,\n",
    "    total_tokens=sum(c.token_count for c in chunks),\n",
    "    chunks=chunks,\n",
    "    status=DocumentStatus.READY\n",
    ")\n",
    "\n",
    "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
    "\n",
    "def progress(idx, total, loss):\n",
    "    print(f\"  Chunk {idx+1}/{total}: loss={loss:.4f}\")\n",
    "\n",
    "metrics = trainer.train_on_document(doc, progress_callback=progress)\n",
    "print(f\"\\n✓ Learning complete:\")\n",
    "print(f\"  Initial loss: {metrics.initial_loss:.4f}\")\n",
    "print(f\"  Final loss: {metrics.final_loss:.4f}\")\n",
    "print(f\"  Time: {metrics.learning_time_seconds:.2f}s\")\n",
    "print(f\"  Weight delta: {metrics.weight_delta_norm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear context and compare answers\n",
    "from src.inference.generator import Generator\n",
    "\n",
    "model.clear_context()\n",
    "gen = Generator(model=model, tokenizer=model.tokenizer)\n",
    "\n",
    "questions = [\n",
    "    \"Who is the CEO of ACME Corporation?\",\n",
    "    \"What is ACME's revenue?\",\n",
    "    \"Where is ACME headquarters located?\",\n",
    "]\n",
    "\n",
    "print(\"Q&A Comparison (TTT learned vs Base model):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in questions:\n",
    "    ttt_ans, base_ans = gen.compare(q, max_tokens=50, temperature=0.0)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"TTT:  {ttt_ans.text[:100]}\")\n",
    "    print(f\"Base: {base_ans.text[:100]}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb397e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Step 8.2: Full Pipeline Test PASSED\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde6ea7",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8.3: Memory Test\n",
    "\n",
    "Process larger PDF, monitor VRAM usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0447933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / 1024**3\n",
    "    return 0\n",
    "\n",
    "def get_gpu_memory_peak():\n",
    "    \"\"\"Get peak GPU memory usage in GB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.max_memory_allocated() / 1024**3\n",
    "    return 0\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "print(f\"Current GPU memory: {get_gpu_memory():.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger test PDF (20 pages)\n",
    "def create_large_pdf(filename: str, num_pages: int = 20):\n",
    "    doc = fitz.open()\n",
    "    content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \" * 50\n",
    "    for i in range(num_pages):\n",
    "        page = doc.new_page()\n",
    "        page.insert_text((50, 50), f\"Page {i+1}\", fontsize=12)\n",
    "        page.insert_text((50, 80), content, fontsize=10)\n",
    "    doc.save(filename)\n",
    "    doc.close()\n",
    "    print(f\"Created {filename} ({num_pages} pages)\")\n",
    "\n",
    "create_large_pdf(\"large_test.pdf\", num_pages=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and chunk\n",
    "with open(\"large_test.pdf\", \"rb\") as f:\n",
    "    text, page_count = parser.parse(f.read())\n",
    "\n",
    "chunker = DocumentChunker(model.tokenizer, chunk_size=2048)\n",
    "chunks = chunker.chunk(text)\n",
    "\n",
    "doc = Document(\n",
    "    id=\"large_test\",\n",
    "    filename=\"large_test.pdf\",\n",
    "    page_count=page_count,\n",
    "    total_tokens=sum(c.token_count for c in chunks),\n",
    "    chunks=chunks,\n",
    "    status=DocumentStatus.READY\n",
    ")\n",
    "\n",
    "print(f\"✓ Large doc: {page_count} pages, {len(chunks)} chunks, {doc.total_tokens} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19497c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and monitor memory\n",
    "model.reset_learning()\n",
    "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
    "\n",
    "memory_samples = []\n",
    "def memory_callback(idx, total, loss):\n",
    "    mem = get_gpu_memory()\n",
    "    memory_samples.append(mem)\n",
    "    print(f\"  Chunk {idx+1}/{total}: loss={loss:.4f}, VRAM={mem:.2f}GB\")\n",
    "\n",
    "metrics = trainer.train_on_document(doc, progress_callback=memory_callback)\n",
    "\n",
    "peak_mem = get_gpu_memory_peak()\n",
    "print(f\"\\n✓ Memory test results:\")\n",
    "print(f\"  Peak VRAM: {peak_mem:.2f} GB\")\n",
    "print(f\"  Max VRAM during learning: {max(memory_samples) if memory_samples else 0:.2f} GB\")\n",
    "\n",
    "# T4 has 16GB, we want to stay under 14GB\n",
    "assert peak_mem < 14.0, f\"Peak VRAM {peak_mem:.2f}GB exceeds 14GB limit!\"\n",
    "print(\"  ✓ VRAM usage within T4 limits (<14GB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ba831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Step 8.3: Memory Test PASSED\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9651b3",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8.4: Latency Test\n",
    "\n",
    "Measure time per chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4787fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "model.reset_learning()\n",
    "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
    "\n",
    "chunk_times = []\n",
    "last_time = perf_counter()\n",
    "\n",
    "def timing_callback(idx, total, loss):\n",
    "    global last_time\n",
    "    now = perf_counter()\n",
    "    elapsed = now - last_time\n",
    "    chunk_times.append(elapsed)\n",
    "    last_time = now\n",
    "    print(f\"  Chunk {idx+1}/{total}: {elapsed:.2f}s\")\n",
    "\n",
    "last_time = perf_counter()\n",
    "metrics = trainer.train_on_document(doc, progress_callback=timing_callback)\n",
    "\n",
    "avg_time = sum(chunk_times) / len(chunk_times) if chunk_times else 0\n",
    "print(f\"\\n✓ Latency test results:\")\n",
    "print(f\"  Average time per chunk: {avg_time:.2f}s\")\n",
    "print(f\"  Total learning time: {metrics.learning_time_seconds:.2f}s\")\n",
    "\n",
    "# Target: <3s per 2048-token chunk on T4\n",
    "assert avg_time < 3.0, f\"Average {avg_time:.2f}s exceeds 3s target!\"\n",
    "print(\"  ✓ Latency within target (<3s per chunk)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Step 8.4: Latency Test PASSED\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cddd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ ALL PHASE 8 INTEGRATION TESTS PASSED!\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
