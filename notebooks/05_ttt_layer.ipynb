{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaratrisrinivas/ttt-playground/blob/main/notebooks/05_ttt_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_GtuEQfo9Vd"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaratrisrinivas/ttt-playground/blob/main/notebooks/05_ttt_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eudtpqOpo9Vf"
      },
      "source": [
        "# Phase 3: TTT-Linear Layer Tests\n",
        "\n",
        "Tests for each step in Phase 3 of plan.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1GxPUPTWo9Vg",
        "outputId": "f1e94927-2879-4331-a987-f1f0e9d1f239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ttt-playground'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 125 (delta 57), reused 81 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (125/125), 59.37 KiB | 5.40 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "/content/ttt-playground\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Working directory: /content/ttt-playground\n"
          ]
        }
      ],
      "source": [
        "# Setup: Clone repo and install dependencies\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "if 'ttt-playground' not in os.getcwd():\n",
        "    !git clone https://github.com/sivaratrisrinivas/ttt-playground.git\n",
        "    %cd ttt-playground\n",
        "\n",
        "if 'content' in os.getcwd() and 'ttt-playground' in os.getcwd():\n",
        "    os.chdir('/content/ttt-playground')\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "print(f\"✓ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92G-N_n9o9Vi"
      },
      "source": [
        "## Step 3.1: Import models package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j0EZHyTpo9Vj",
        "outputId": "8c2dacb1-690f-48e9-d38a-91f8cb76118f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Step 3.1: from src.models import * succeeds\n"
          ]
        }
      ],
      "source": [
        "from src.models import *\n",
        "print(\"✓ Step 3.1: from src.models import * succeeds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGtqb4xxo9Vk"
      },
      "source": [
        "## Step 3.2: TTTLinear.__init__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PHgAV5tto9Vl",
        "outputId": "de4c2ba0-3d3a-44bf-ca57-8051ce85074d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ TTTLinear instantiated\n",
            "  W_h.shape: torch.Size([2048, 768])\n",
            "✓ Step 3.2: W_h.shape == (2048, 768) verified\n"
          ]
        }
      ],
      "source": [
        "from src.models.ttt_linear import TTTLinear\n",
        "\n",
        "layer = TTTLinear(768, 2048, 768)\n",
        "print(f\"✓ TTTLinear instantiated\")\n",
        "print(f\"  W_h.shape: {layer.W_h.shape}\")\n",
        "assert layer.W_h.shape == (2048, 768), f\"Expected (2048, 768), got {layer.W_h.shape}\"\n",
        "print(\"✓ Step 3.2: W_h.shape == (2048, 768) verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAMN5Mf3o9Vm"
      },
      "source": [
        "## Step 3.3: TTTLinear.forward (inference mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "489lAIBOo9Vn",
        "outputId": "efc36d09-5b96-41a0-e240-baab4bad0cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "_forward_unimplemented() got an unexpected keyword argument 'learning'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1575380545.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Test forward pass - inference mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Input shape: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Output shape: {y.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _forward_unimplemented() got an unexpected keyword argument 'learning'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Test forward pass - inference mode\n",
        "x = torch.randn(1, 128, 768)\n",
        "y = layer(x, learning=False)\n",
        "print(f\"  Input shape: {x.shape}\")\n",
        "print(f\"  Output shape: {y.shape}\")\n",
        "assert y.shape == (1, 128, 768), f\"Expected (1, 128, 768), got {y.shape}\"\n",
        "print(\"✓ Step 3.3: Output shape [1, 128, 768] verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3-II3uro9Vn"
      },
      "source": [
        "## Step 3.4: Initial weights stored for reset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHHoqnamo9Vo"
      },
      "outputs": [],
      "source": [
        "# Verify _W_h_initial exists and matches W_h\n",
        "assert hasattr(layer, '_W_h_initial'), \"Missing _W_h_initial attribute\"\n",
        "assert torch.allclose(layer.W_h, layer._W_h_initial), \"W_h should match _W_h_initial after init\"\n",
        "print(\"✓ Step 3.4: _W_h_initial stored and matches W_h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKlHscrzo9Vo"
      },
      "source": [
        "## Step 3.5: TTTLinear.forward (learning mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_d3khtBo9Vp"
      },
      "outputs": [],
      "source": [
        "# Create fresh layer for learning test\n",
        "layer = TTTLinear(768, 2048, 768)\n",
        "w_before = layer.W_h.clone()\n",
        "\n",
        "x = torch.randn(1, 128, 768)\n",
        "y = layer(x, learning=True)\n",
        "\n",
        "assert not torch.allclose(layer.W_h, w_before), \"W_h should change after learning=True\"\n",
        "print(\"✓ Step 3.5: W_h differs from initial after learning=True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YAezTTDo9Vp"
      },
      "source": [
        "## Step 3.6: reset_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irDrvppIo9Vp"
      },
      "outputs": [],
      "source": [
        "# Reset and verify\n",
        "layer.reset_weights()\n",
        "assert torch.allclose(layer.W_h, layer._W_h_initial), \"W_h should match _W_h_initial after reset\"\n",
        "print(\"✓ Step 3.6: reset_weights() restores initial W_h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Q1bt8io9Vq"
      },
      "source": [
        "## Step 3.7: get_weight_delta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qudV0n1Zo9Vq"
      },
      "outputs": [],
      "source": [
        "# Learn then check delta\n",
        "layer = TTTLinear(768, 2048, 768)\n",
        "x = torch.randn(1, 128, 768)\n",
        "layer(x, learning=True)\n",
        "\n",
        "delta = layer.get_weight_delta()\n",
        "print(f\"  Weight delta: {delta}\")\n",
        "assert delta > 0, \"Weight delta should be > 0 after learning\"\n",
        "print(\"✓ Step 3.7: get_weight_delta() > 0 after learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqs2edy1o9Vq"
      },
      "source": [
        "## Step 3.8: Gradient flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK3JBDLso9Vr"
      },
      "outputs": [],
      "source": [
        "# Test gradient flow through layer\n",
        "layer = TTTLinear(768, 2048, 768)\n",
        "x = torch.randn(1, 128, 768, requires_grad=True)\n",
        "y = layer(x, learning=False)\n",
        "loss = y.sum()\n",
        "loss.backward()\n",
        "\n",
        "assert x.grad is not None, \"Input gradient should not be None\"\n",
        "print(\"✓ Step 3.8: Gradient flows through layer (input.grad is not None)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ ALL PHASE 3 TESTS PASSED!\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}